# M_L
Machine learning repo

1)  Decision tree regression is a supervised learning technique used to predict continuous outcomes based on input features. It utilizes a tree-like model where each internal node represents a decision based on an attribute, each branch represents the outcome of that decision, and each leaf node represents a predicted value.
Advantages:
    Decision trees are easy to interpret and visualize.
    They can handle both numerical and categorical data.
    They do not require feature scaling.
Disadvantages:
    Decision trees can be prone to overfitting, especially if they are deep. This means they may capture noise in the training data rather than the underlying distribution.
    They can be unstable; small changes in the data can lead to different tree structures



2)  The k-nearest neighbors (k-NN) algorithm is a non-parametric, supervised learning method used for classification and regression. It is one of the simplest machine learning algorithms to understand and implement.
The k-NN algorithm assumes that similar things exist in close proximity. It classifies a data point by looking at the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:
    In k-NN classification, the output is a class membership. The data point is assigned to the class most common among its k nearest neighbors.
    In k-NN regression, the output is the property value for the object. This value is the average of the values of its k nearest neighbors